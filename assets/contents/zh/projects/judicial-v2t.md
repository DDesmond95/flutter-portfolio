---
title: "Judicial V2T ‚Äî Secure Speech-to-Text for Court Systems"
slug: "judicial-v2t"
type: "project"
visibility: "private"
date: "2024-06-12"
summary: "An offline voice-to-text system designed for judicial transcription ‚Äî accuracy, privacy, and resilience."
tags: ["speech recognition", "AI systems", "FastAPI", "LLMOps", "security"]
thumbnail: "/assets/images/covers/default-project.webp"
---

# Judicial V2T ‚Äî Secure Speech-to-Text System

## üß© Overview

Judicial V2T is an **on-premise speech transcription system** designed for use in courtrooms and legal institutions.  
It transforms complex multi-speaker recordings into structured, timestamped transcripts without sending any data to external APIs.

---

## ‚ö†Ô∏è Problem

Courts in many regions rely on manual transcription or cloud-based APIs that compromise confidentiality.  
Key challenges:

- Sensitive data could not leave premises.
- Human transcription was time-consuming and error-prone.
- Network instability made cloud ASR unreliable.
- Multilingual proceedings (English + Malay + Mandarin) demanded adaptive models.

---

## üß† Solution

A self-contained Whisper-based transcription engine, deployed locally via **FastAPI** and **Docker**, integrating multilingual ASR, diarization, and formatting layers.

Features:

- **Offline inference** using fine-tuned Whisper models.
- **Noise reduction pipeline** with PyTorch + RNNoise.
- **Speaker segmentation** (pyannote.audio).
- **Legal formatting layer** for timestamped transcripts.
- **Role-based dashboard** for playback, correction, and audit logging.

---

## ‚öôÔ∏è Architecture

```plaintext
Audio Input ‚Üí Preprocessing ‚Üí Whisper ASR ‚Üí Diarization ‚Üí Postprocess (Formatting + Timestamp)
                                     ‚Üì
                              API Gateway (FastAPI)
                                     ‚Üì
                               Local Dashboard (Flutter)
```

Security:

- All data stored on encrypted SSDs (AES-256).
- Network air-gapped.
- Logs anonymised and rotated automatically.

---

## üìà Results

| Metric                     | Before                | After          |
| -------------------------- | --------------------- | -------------- |
| Average transcription time | 4‚Äì6 hours per session | < 20 minutes   |
| Human correction load      | 100%                  | ~15%           |
| Data leakage risk          | High (cloud API)      | None (on-prem) |

---

## üî¨ Lessons

- CPU inference with quantized Whisper is viable for small installations.
- Pre-computing MFCCs saves 25 % runtime.
- Human-in-loop feedback improved model precision for legal vocabulary.

---

## ‚öñÔ∏è Ethics & Fairness

- No external connectivity: privacy guaranteed.
- Explicit audit logs for each access.
- All training data obtained from publicly available recordings.

---

## üîÆ Next Steps

- Integrate speaker ID with biometric registry.
- Add summarization layer for case metadata.
- Publish internal whitepaper (restricted circulation).

_Status: Internal production deployment ¬∑ Visibility: Private_
